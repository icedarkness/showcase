1:"$Sreact.fragment"
2:I[7555,[],""]
3:I[1295,[],""]
4:I[9665,[],"OutletBoundary"]
7:I[4911,[],"AsyncMetadataOutlet"]
9:I[9665,[],"ViewportBoundary"]
b:I[9665,[],"MetadataBoundary"]
d:I[6614,[],""]
:HL["/github_showcase/_next/static/css/0502a9f2e43f566f.css","style"]
:HL["/github_showcase/_next/static/css/9468c63d5d5149c4.css","style"]
:HL["/github_showcase/_next/static/css/ad27c676daf4b70e.css","style"]
0:{"P":null,"b":"DC_AsRnDh2EAZ6avNJ00F","p":"/github_showcase","c":["",""],"i":false,"f":[[["",{"children":["__PAGE__",{}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/github_showcase/_next/static/css/0502a9f2e43f566f.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","link","1",{"rel":"stylesheet","href":"/github_showcase/_next/static/css/9468c63d5d5149c4.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","link","2",{"rel":"stylesheet","href":"/github_showcase/_next/static/css/ad27c676daf4b70e.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","children":["$","body",null,{"className":"__className_c7d122","children":["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]}]]}],{"children":["__PAGE__",["$","$1","c",{"children":[["$","div",null,{"className":"container mt-5","children":[null,["$","header",null,{"className":"text-center mb-5","children":[["$","h1",null,{"className":"display-4","children":"Wen Zhang"}],["$","p",null,{"className":"lead","children":"Data Scientist"}],["$","p",null,{"children":[["$","a",null,{"href":"https://www.linkedin.com/in/wenzhangdatascientist/","target":"_blank","rel":"noopener noreferrer","className":"btn btn-outline-primary me-2","children":"LinkedIn"}],["$","a",null,{"href":"http://icedarkness.github.io/","target":"_blank","rel":"noopener noreferrer","className":"btn btn-outline-secondary","children":"GitHub"}],["$","a",null,{"href":"/Wen_Zhang_Principal_Data_Scientist_Resume.pdf","download":true,"className":"btn btn-outline-success ms-2","children":"Download Resume"}]]}]]}],["$","main",null,{"children":[["$","section",null,{"id":"about","className":"mb-5","children":[["$","h2",null,{"children":"About Me"}],["$","p",null,{"children":"I am a passionate Data Scientist with a deep background in the banking, specialty finance, and fintech sectors. My work focuses on transforming complex data into actionable insights that solve real-world problems. I specialize in developing and deploying robust predictive models, from FCRA-compliant credit risk systems to non-FCRA models for small business lending."}],["$","p",null,{"children":"I am highly skilled in modernizing legacy systems and automating analytics pipelines to enhance scalability and efficiency. My technical toolkit includes Python, SQL, SAS, and a variety of machine learning frameworks. I hold a Master of Science in Applied Statistics & Operational Research and am a certified Deep Learning specialist. I am driven by the challenge of finding elegant, data-driven solutions that improve decision-making and create a measurable impact."}]]}],["$","section",null,{"id":"skills","className":"mb-5","children":[["$","h2",null,{"children":"Skills"}],["$","ul",null,{"children":[["$","li",null,{"children":[["$","strong",null,{"children":"Statistical Machine Learning:"}]," GBM (XGBoost), Random Forest, SVM, KNN, AdaBoost, LSTM, Logistic Regression"]}],["$","li",null,{"children":[["$","strong",null,{"children":"Data Analytics:"}]," Data Mining & Validation, Big Data Analytics, ETL Processes, Credit Scoring"]}],["$","li",null,{"children":[["$","strong",null,{"children":"Risk Modeling:"}]," Predictive Risk Modeling, Financial Risk Modeling, Fraud Detection & Prevention"]}],["$","li",null,{"children":[["$","strong",null,{"children":"Optimization Methods:"}]," Stochastic Processes, Linear Programming, Multi-Objective Optimization (NSGA-II)"]}],["$","li",null,{"children":[["$","strong",null,{"children":"Programming & Tools:"}]," Python, SQL, SAS, Angoss"]}],["$","li",null,{"children":[["$","strong",null,{"children":"Certifications:"}]," Deep Learning Specialization"]}]]}]]}],["$","section",null,{"id":"projects","children":[["$","h2",null,{"children":"Projects"}],[["$","div","0",{"className":"card mb-3","children":["$","div",null,{"className":"card-body","children":[["$","h5",null,{"className":"card-title","children":"Lending Club Credit Risk Model with XAI"}],["$","p",null,{"className":"card-text","children":"This project demonstrates a complete, end-to-end workflow for building and interpreting a credit risk model on the Lending Club dataset. The primary objective is to predict loan defaults (\"Charged Off\") while maintaining a strong focus on Explainable AI (XAI). The analysis begins with memory-efficient data ingestion and preprocessing of a large dataset, followed by feature engineering to create impactful predictors. A LightGBM model is trained and evaluated using metrics suitable for imbalanced data, such as ROC AUC and Precision-Recall curves. The core of the project lies in using the SHAP library to interpret the model's decisions, providing both global feature importance and local, instance-level explanations for why a specific loan is predicted to default or be paid off."}],["$","p",null,{"className":"card-text","children":["$","small",null,{"className":"text-muted","children":"Python, Pandas, LightGBM, SHAP, Scikit-learn, Jupyter Notebook"}]}],["$","a",null,{"href":"https://github.com/icedarkness/showcase/blob/main/Lending%20Club%20Credit%20Risk%20Model%20with%20XAI/Lending%20Club%20Credit%20Risk%20Model%20with%20XAI.ipynb","className":"btn btn-primary","target":"_blank","rel":"noopener noreferrer","children":"View on GitHub"}]]}]}],["$","div","1",{"className":"card mb-3","children":["$","div",null,{"className":"card-body","children":[["$","h5",null,{"className":"card-title","children":"RAG-Powered Chatbot for Financial Product Information"}],["$","p",null,{"className":"card-text","children":"This project features a web-based chatbot designed to answer user questions about a fictional bank's financial products. It leverages a Retrieval-Augmented Generation (RAG) pipeline to ensure answers are accurate and grounded in a specific knowledge base. The application is built as a self-contained HTML file for easy deployment and showcases modern AI techniques, including using `sentence-transformers` for embeddings and `FAISS` for efficient vector search. A key feature is the chatbot's ability to cite its sources, providing transparency by showing the user which part of the knowledge base was used to generate the answer."}],["$","p",null,{"className":"card-text","children":["$","small",null,{"className":"text-muted","children":"RAG, Gemini API, Sentence-Transformers, FAISS, HTML, CSS"}]}],["$","a",null,{"href":"https://github.com/icedarkness/showcase/tree/main/RAG-Powered%20Financial%20Chatbot","className":"btn btn-primary","target":"_blank","rel":"noopener noreferrer","children":"View on GitHub"}]]}]}],["$","div","2",{"className":"card mb-3","children":["$","div",null,{"className":"card-body","children":[["$","h5",null,{"className":"card-title","children":"German Credit Risk Model with XAI"}],["$","p",null,{"className":"card-text","children":"This project involves building a highly accurate classification model to predict credit risk using the well-known German Credit Data (Statlog) dataset. The workflow begins with a thorough exploratory data analysis (EDA) to understand the relationships between features like age, credit purpose, and loan duration. A robust preprocessing pipeline is created using scikit-learn's `ColumnTransformer` to handle numerical and categorical data appropriately. A RandomForestClassifier is trained and evaluated, but the core focus is on Explainable AI (XAI). The SHAP library is used to interpret the model's decisions, providing both global feature importance and local, instance-level explanations to answer questions like, \"Why was this specific applicant flagged as a high risk?\""}],["$","p",null,{"className":"card-text","children":["$","small",null,{"className":"text-muted","children":"Python, Pandas, Scikit-learn, RandomForest, SHAP, Matplotlib, Seaborn"}]}],["$","a",null,{"href":"https://github.com/icedarkness/showcase/blob/main/German%20Credit%20Data%20(Statlog)/German_Credit_Data.ipynb","className":"btn btn-primary","target":"_blank","rel":"noopener noreferrer","children":"View on GitHub"}]]}]}],["$","div","3",{"className":"card mb-3","children":["$","div",null,{"className":"card-body","children":[["$","h5",null,{"className":"card-title","children":"Customer Segmentation for Targeted Marketing in Lending"}],["$","p",null,{"className":"card-text","children":"This project showcases the use of unsupervised machine learning to drive business strategy. Using the classic \"Mall Customer\" dataset, this analysis applies K-Means clustering to segment customers based on their financial profiles, specifically annual income and spending score. The workflow includes a thorough exploratory data analysis (EDA), using the Elbow Method to determine the optimal number of clusters, and building the final segmentation model. The core of the project is the interpretation of these clusters, where distinct customer personas (e.g., \"The Savers,\" \"The High Rollers\") are created. Finally, actionable, targeted marketing strategies are proposed for each segment from a lending perspective, demonstrating how data-driven insights can inform business decisions."}],["$","p",null,{"className":"card-text","children":["$","small",null,{"className":"text-muted","children":"Python, Pandas, Scikit-learn (K-Means, StandardScaler), Matplotlib, Seaborn"}]}],["$","a",null,{"href":"https://github.com/icedarkness/showcase/blob/main/Customer%20Segmentation%20for%20Marketing/Customer%20Segmentation%20for%20Marketing.ipynb","className":"btn btn-primary","target":"_blank","rel":"noopener noreferrer","children":"View on GitHub"}]]}]}],["$","div","4",{"className":"card mb-3","children":["$","div",null,{"className":"card-body","children":[["$","h5",null,{"className":"card-title","children":"Time-Series Forecasting of Loan Portfolio Performance"}],["$","p",null,{"className":"card-text","children":"This project showcases time-series analysis and forecasting, a critical skill for financial planning and risk management. A realistic, synthetic dataset of monthly loan defaults is generated to include a clear trend and seasonality, mimicking real-world portfolio performance. The core of the project involves using Facebook's Prophet, a powerful forecasting library, to build a model that predicts future default volumes. The analysis includes visualizing the forecast along with its uncertainty intervals and decomposing the time series into its underlying trend and seasonal components to provide a clear interpretation of the factors driving the predictions."}],["$","p",null,{"className":"card-text","children":["$","small",null,{"className":"text-muted","children":"Python, Pandas, Prophet, Matplotlib"}]}],["$","a",null,{"href":"https://github.com/icedarkness/showcase/tree/main/Time-Series%20Forecasting%20of%20Loan%20Volume%20(SARIMA%20vs.%20Prophet)","className":"btn btn-primary","target":"_blank","rel":"noopener noreferrer","children":"View on GitHub"}]]}]}]]]}]]}],["$","footer",null,{"className":"text-center mt-5 py-3","children":["$","p",null,{"children":["© ",2025," Wen Zhang"]}]}]]}],null,["$","$L4",null,{"children":["$L5","$L6",["$","$L7",null,{"promise":"$@8"}]]}]]}],{},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","iUSugUToVxJcV0VLXSD1lv",{"children":[["$","$L9",null,{"children":"$La"}],null]}],["$","$Lb",null,{"children":"$Lc"}]]}],false]],"m":"$undefined","G":["$d","$undefined"],"s":false,"S":true}
e:"$Sreact.suspense"
f:I[4911,[],"AsyncMetadata"]
c:["$","div",null,{"hidden":true,"children":["$","$e",null,{"fallback":null,"children":["$","$Lf",null,{"promise":"$@10"}]}]}]
6:null
a:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
5:null
8:{"metadata":[["$","title","0",{"children":"Wen Zhang - Data Scientist"}],["$","meta","1",{"name":"description","content":"Personal portfolio of Wen Zhang, a Data Scientist specializing in predictive modeling and machine learning."}],["$","link","2",{"rel":"icon","href":"/github_showcase/favicon.ico","type":"image/x-icon","sizes":"16x16"}]],"error":null,"digest":"$undefined"}
10:{"metadata":"$8:metadata","error":null,"digest":"$undefined"}
